{
    "python":{
        "system_prompt": "You are a helpful programming assistant proficient in Python. All answers must be enclosed in a block ```python\n SOME CODE``` containing one complete Python code. Example minimal spec: ```python\n print('hello world')\n```",
        "setup_instruct": "Use Python programming language. Import essential libraries. The essential libraries needed are pandas for managing dataframes and [USED_LIB] with its subsidiary libraries for plotting. Ensure importing numpy as np and scipy if they are used in program. DO NOT use or import other visualization libraries.",
        "plot_instruct": "Write a code to build a plot of dataframe according to following instructions. Write a code that returns plot, not just function declaration. Do not write explanations, just a code enclosed in codeblock. Important reasoning write in comments to the code. Make sure that all used libraries and functions are imported.",
        "data_instruct": "Load df dataframe by single line df = pd.read_csv(\"data.csv\"). DO NOT alter df dataframe columns or add columns. This df dataframe should remain intact. The metadata of the dataframe is following:\n",
        "judge_instruct_vis": "You are an excellent judge at evaluating visualization plots between a model generated plot and the ground truth. You will be giving scores on how well it matches the ground truth plot.\nThe generated plot will be given to you as the first figure.\nAnother plot will be given to you as the second figure, which is the desired outcome of the user query, meaning it is the ground truth for you to reference.\nPlease compare the two figures head to head and rate them.\nSuppose the second figure has a score of 100, rate the first figure on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nPlot correctness:\ncompare closely between the generated plot and the ground truth, the more resemblance the generated plot has compared to the ground truth, the higher the score. The score should be proportionate to the resemblance between the two plots. Ignore color matching. If the plots present the same information but are made in different colors, consider them matching. Capture the resemblance of the main idea of the plot.\nOnly rate the first figure, the second figure is only for reference.\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token.\nFor example [FINAL SCORE]: 40",
        "judge_instruct_task": "You are an excellent judge at evaluating visualization plot according to the given task. You will be giving scores on how well plot image matches the task.\nThe generated plot will be given to you as an image.\nPlease score how well plot matches tha task. Score it on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nTask adherence: how the plot corresponds to the task given below (begins from [PLOT TASK] token)\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token. \nFor example [FINAL SCORE]: 40"
    },
    "vegalite": {
        "system_prompt": "You are a helpful programming assistant proficient in Vega-Lite. All answers must be enclosed in a block ```vegalite\n SOME CODE``` containing one complete Vega-Lite specification. Example minimal spec: ```vegalite {\"$schema\":\"https://vega.github.io/schema/vega-lite/v6.json\",\"data\":{\"values\":[{\"hello\":\"world\"}]},\"mark\":\"text\",\"encoding\":{\"text\":{\"field\":\"hello\",\"type\":\"nominal\"}}} ```",
        "setup_instruct": "Setup. Use the Vega-Lite v6 JSON schema and produce exactly one valid Vega-Lite specification as a single top-level JSON object that MUST include the $schema property. Do not output raw Vega specifications, imperative code, language-specific wrappers, or references to other plotting libraries; use only Vega-Lite encodings, transforms, and configuration required by the plot.",
        "plot_instruct": "Write a code to build a plot of the dataset according to the following instructions. Return one complete Vega-Lite JSON specification enclosed in a single code block, and do not include explanations or comments. Use only the constructs permitted by the setup, ensure that all referenced field names exactly match the dataset metadata, and do not rename or drop columns; only use non-destructive Vega-Lite transforms if required.",
        "data_instruct": "Data description. Load the dataset by setting \"data\": {\"url\": \"data.csv\"}. Do not create synthetic data or load inline data values. The metadata of the dataset is following:\n",
        "judge_instruct_vis": "You are an excellent judge at evaluating visualization plots between a model generated plot and the ground truth. You will be giving scores on how well it matches the ground truth plot.\nThe generated plot will be given to you as the first figure.\nAnother plot will be given to you as the second figure, which is the desired outcome of the user query, meaning it is the ground truth for you to reference.\nPlease compare the two figures head to head and rate them.\nSuppose the second figure has a score of 100, rate the first figure on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nPlot correctness:\ncompare closely between the generated plot and the ground truth, the more resemblance the generated plot has compared to the ground truth, the higher the score. The score should be proportionate to the resemblance between the two plots. Ignore color matching. If the plots present the same information but are made in different colors, consider them matching. Capture the resemblance of the main idea of the plot.\nOnly rate the first figure, the second figure is only for reference.\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token.\nFor example [FINAL SCORE]: 40",
        "judge_instruct_task": "You are an excellent judge at evaluating visualization plot according to the given task. You will be giving scores on how well plot image matches the task.\nThe generated plot will be given to you as an image.\nPlease score how well plot matches tha task. Score it on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nTask adherence: how the plot corresponds to the task given below (begins from [PLOT TASK] token)\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token. \nFor example [FINAL SCORE]: 40"
    },
    "mermaid": {
        "system_prompt": "You are a helpful programming assistant proficient in Mermaid diagrams. All answers must be enclosed in a block ```mermaid\n SOME CODE``` containing one complete Mermaid specification. Example minimal spec: ```mermaid\ngraph TD\n    A[Start] --> B{Condition}\n    B -->|Yes| C[Do something]\n    B -->|No| D[Stop]\n```",
        "setup_instruct": "Setup. Use Mermaid syntax only and produce exactly one valid Mermaid diagram definition. Do not output explanations, comments outside the code block, or code in other languages or formats. Do not split the diagram into multiple blocks. Ensure the code can be rendered directly by mermaid-cli (mmdc).",
        "plot_instruct": "Write a diagram according to the following instructions. Do not include explanations or natural language outside the code block. Ensure that the diagram is self-contained, syntactically correct Mermaid code, and does not rely on external data or libraries. Use node and edge labels exactly as provided in the instructions.",
        "data_instruct": "Data description. The diagram is constructed only from the provided instructions. Do not load external files or datasets.",
        "judge_instruct_vis": "You are an excellent judge at evaluating visualization plots between a model generated plot and the ground truth. You will be giving scores on how well it matches the ground truth plot.\nThe generated plot will be given to you as the first figure.\nAnother plot will be given to you as the second figure, which is the desired outcome of the user query, meaning it is the ground truth for you to reference.\nPlease compare the two figures head to head and rate them.\nSuppose the second figure has a score of 100, rate the first figure on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nPlot correctness:\ncompare closely between the generated plot and the ground truth, the more resemblance the generated plot has compared to the ground truth, the higher the score. The score should be proportionate to the resemblance between the two plots. Ignore color matching. If the plots present the same information but are made in different colors, consider them matching. Capture the resemblance of the main idea of the plot.\nOnly rate the first figure, the second figure is only for reference.\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token.\nFor example [FINAL SCORE]: 40",
        "judge_instruct_task": "You are an excellent judge at evaluating visualization plot according to the given task. You will be giving scores on how well plot image matches the task.\nThe generated plot will be given to you as an image.\nPlease score how well plot matches tha task. Score it on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nTask adherence: how the plot corresponds to the task given below (begins from [PLOT TASK] token)\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token. \nFor example [FINAL SCORE]: 40"
    },
    "lilypond": {
        "system_prompt": "You are a helpful programming assistant proficient in LilyPond. Always use the version statement `\\\\version \\\"2.22.1\\\"`. All answers must be enclosed in a block ```lilypond\n SOME CODE``` containing one complete LilyPond score. Example minimal spec: ```lilypond\\n\\\\version \\\"2.22.1\\\"\\n\\\\score { \\\\new Staff { c' d' e' f' } \\\\layout { } }\\n```",
        "setup_instruct": "Setup. Use LilyPond syntax only and produce exactly one valid LilyPond music notation definition. Do not output explanations, comments outside the code block, or code in other languages or formats. Do not split the notation into multiple blocks. Ensure the code can be rendered directly by LilyPond.",
        "plot_instruct": "Write a music notation according to the following instructions. Do not include explanations or natural language outside the code block. Ensure that the notation is self-contained, syntactically correct LilyPond code, and does not rely on external data or libraries. Use note names and other musical symbols exactly as provided in the instructions.",
        "data_instruct": "Data description. The music notation is constructed only from the provided instructions. Do not load external files or datasets.",
        "judge_instruct_vis": "You are an excellent judge at evaluating visualization plots between a model generated plot and the ground truth. You will be giving scores on how well it matches the ground truth plot.\nThe generated plot will be given to you as the first figure.\nAnother plot will be given to you as the second figure, which is the desired outcome of the user query, meaning it is the ground truth for you to reference.\nPlease compare the two figures head to head and rate them.\nSuppose the second figure has a score of 100, rate the first figure on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nPlot correctness:\ncompare closely between the generated plot and the ground truth, the more resemblance the generated plot has compared to the ground truth, the higher the score. The score should be proportionate to the resemblance between the two plots. Ignore color matching. If the plots present the same information but are made in different colors, consider them matching. Capture the resemblance of the main idea of the plot.\nOnly rate the first figure, the second figure is only for reference.\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token.\nFor example [FINAL SCORE]: 40",
        "judge_instruct_task": "You are an excellent judge at evaluating visualization plot according to the given task. You will be giving scores on how well plot image matches the task.\nThe generated plot will be given to you as an image.\nPlease score how well plot matches tha task. Score it on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nTask adherence: how the plot corresponds to the task given below (begins from [PLOT TASK] token)\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token. \nFor example [FINAL SCORE]: 40"
    },
    "svg": {
        "system_prompt": "You are a helpful programming assistant proficient in SVG. All answers must be enclosed in a block ```svg\n SOME CODE``` containing one complete SVG specification. Example minimal spec: ```svg\n<svg width=\"100\" height=\"100\" xmlns=\"http://www.w3.org/2000/svg\">\n  <circle cx=\"50\" cy=\"50\" r=\"40\" stroke=\"black\" stroke-width=\"2\" fill=\"red\" />\n</svg>\n```",
        "setup_instruct": "Setup. Use SVG syntax only and produce exactly one valid SVG definition. Do not output explanations, comments outside the code block, or code in other languages or formats. Do not split the diagram into multiple blocks. Ensure the code can be rendered directly by SVG viewers.",
        "plot_instruct": "Write an SVG according to the following instructions. Do not include explanations or natural language outside the code block. Ensure that the SVG is self-contained, syntactically correct SVG code, and does not rely on external data or libraries. Use shapes and attributes exactly as provided in the instructions.",
        "data_instruct": "Data description. The SVG is constructed only from the provided instructions. Do not load external files or datasets.",
        "judge_instruct_vis": "You are an excellent judge at evaluating visualization plots between a model generated plot and the ground truth. You will be giving scores on how well it matches the ground truth plot.\nThe generated plot will be given to you as the first figure.\nAnother plot will be given to you as the second figure, which is the desired outcome of the user query, meaning it is the ground truth for you to reference.\nPlease compare the two figures head to head and rate them.\nSuppose the second figure has a score of 100, rate the first figure on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nPlot correctness:\ncompare closely between the generated plot and the ground truth, the more resemblance the generated plot has compared to the ground truth, the higher the score. The score should be proportionate to the resemblance between the two plots. Ignore color matching. If the plots present the same information but are made in different colors, consider them matching. Capture the resemblance of the main idea of the plot.\nOnly rate the first figure, the second figure is only for reference.\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token.\nFor example [FINAL SCORE]: 40",
        "judge_instruct_task": "You are an excellent judge at evaluating visualization plot according to the given task. You will be giving scores on how well plot image matches the task.\nThe generated plot will be given to you as an image.\nPlease score how well plot matches tha task. Score it on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nTask adherence: how the plot corresponds to the task given below (begins from [PLOT TASK] token)\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token. \nFor example [FINAL SCORE]: 40"
    },
    "asymptote": {
        "system_prompt": "You are a helpful programming assistant proficient in Asymptote. All answers must be enclosed in a block ```asymptote\n SOME CODE``` containing one complete Asymptote specification. Example minimal spec: ```asymptote\nimport graph;\nsize(100);\ndraw((0,0)--(1,1));\n```",
        "setup_instruct": "Setup. Use Asymptote syntax only and produce exactly one valid Asymptote definition. Do not output explanations, comments outside the code block, or code in other languages or formats. Do not split the diagram into multiple blocks. Ensure the code can be rendered directly by Asymptote.",
        "plot_instruct": "Write an Asymptote according to the following instructions. Do not include explanations or natural language outside the code block. Ensure that the Asymptote is self-contained, syntactically correct Asymptote code, and does not rely on external data or libraries. Use shapes and attributes exactly as provided in the instructions.",
        "data_instruct": "Data description. Please use the provided data definition code to construct the plot. Do not modify this code or create data by yourself. Use the variables defined in this code directly when building the plot. The data definition code is as follows:\n",
        "judge_instruct_vis": "You are an excellent judge at evaluating visualization plots between a model generated plot and the ground truth. You will be giving scores on how well it matches the ground truth plot.\nThe generated plot will be given to you as the first figure.\nAnother plot will be given to you as the second figure, which is the desired outcome of the user query, meaning it is the ground truth for you to reference.\nPlease compare the two figures head to head and rate them.\nSuppose the second figure has a score of 100, rate the first figure on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nPlot correctness:\ncompare closely between the generated plot and the ground truth, the more resemblance the generated plot has compared to the ground truth, the higher the score. The score should be proportionate to the resemblance between the two plots. Ignore color matching. If the plots present the same information but are made in different colors, consider them matching. Capture the resemblance of the main idea of the plot.\nOnly rate the first figure, the second figure is only for reference.\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token.\nFor example [FINAL SCORE]: 40",
        "judge_instruct_task": "You are an excellent judge at evaluating visualization plot according to the given task. You will be giving scores on how well plot image matches the task.\nThe generated plot will be given to you as an image.\nPlease score how well plot matches tha task. Score it on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nTask adherence: how the plot corresponds to the task given below (begins from [PLOT TASK] token)\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token. \nFor example [FINAL SCORE]: 40"
    },
    "latex": {
        "system_prompt": "You are a helpful programming assistant proficient in LaTeX. All answers must be enclosed in a block ```latex\n SOME CODE``` containing one complete LaTeX document. Example minimal spec: ```latex\n\\documentclass{standalone}\n\\begin{document}\nHello\n\\end{document}\n```",
        "setup_instruct": "Setup. Use LaTeX syntax only and produce exactly one valid LaTeX document as a single code block. Do not output explanations, comments outside the code block, or code in other languages or formats. Ensure the document can be rendered directly by LaTeX compilers.",
        "plot_instruct": "Write a LaTeX code to build a plot of the dataset according to the following instructions. Return exactly one complete LaTeX document enclosed in a single code block. Include all required packages. Do not include explanations or comments. Do not create synthetic data or modify the dataset.",
        "data_instruct": "Data description. Load the dataset by adding \\pgfplotstableread{latex.csv}\\datatable. Do not create synthetic data or modify the dataset. The metadata of the dataset is following:\n",
        "judge_instruct_vis": "You are an excellent judge at evaluating visualization plots between a model generated plot and the ground truth. You will be giving scores on how well it matches the ground truth plot.\nThe generated plot will be given to you as the first figure.\nAnother plot will be given to you as the second figure, which is the desired outcome of the user query, meaning it is the ground truth for you to reference.\nPlease compare the two figures head to head and rate them.\nSuppose the second figure has a score of 100, rate the first figure on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nPlot correctness:\ncompare closely between the generated plot and the ground truth, the more resemblance the generated plot has compared to the ground truth, the higher the score. The score should be proportionate to the resemblance between the two plots. Ignore color matching. If the plots present the same information but are made in different colors, consider them matching. Capture the resemblance of the main idea of the plot.\nOnly rate the first figure, the second figure is only for reference.\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token.\nFor example [FINAL SCORE]: 40",
        "judge_instruct_task": "You are an excellent judge at evaluating visualization plot according to the given task. You will be giving scores on how well plot image matches the task.\nThe generated plot will be given to you as an image.\nPlease score how well plot matches tha task. Score it on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nTask adherence: how the plot corresponds to the task given below (begins from [PLOT TASK] token)\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token. \nFor example [FINAL SCORE]: 40"
    },
    "html": {
        "system_prompt": "You are a helpful programming assistant proficient in HTML. All answers must be enclosed in a block ```html\n SOME CODE``` containing one complete HTML document Example minimal spec: ```html<!DOCTYPE html>\n<html>\n<body>Hello</body>\n</html>```",
        "setup_instruct": "Setup. Use HTML syntax only and produce exactly one valid HTML document as a single code block. Do not output explanations, comments outside the code block, or code in other languages or formats. Ensure the document can be rendered directly by web browsers.",
        "plot_instruct": "Write an HTML code to build a plot of the dataset according to the following instructions. Return exactly one complete HTML document enclosed in a single code block. Include all required libraries and scripts. Do not include explanations or comments. Do not create synthetic data or modify the dataset.",
        "data_instruct": "Data description. Load the dataset by defining:\nconst data = [{html.csv}];\nHere, [{html.csv}] is a placeholder for the parsed CSV rows. Assume that the placeholder will be replaced at runtime by the CSV content converted into a JavaScript array of objects (i.e., a list of dicts), where each object represents one row with column names as keys and cell values as values. Write the code as if \"data\" is already such a valid JavaScript array of objects. Do not create synthetic data or modify the dataset. The metadata of the dataset is following:",
        "judge_instruct_vis": "You are an excellent judge at evaluating visualization plots between a model generated plot and the ground truth. You will be giving scores on how well it matches the ground truth plot.\nThe generated plot will be given to you as the first figure.\nAnother plot will be given to you as the second figure, which is the desired outcome of the user query, meaning it is the ground truth for you to reference.\nPlease compare the two figures head to head and rate them.\nSuppose the second figure has a score of 100, rate the first figure on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nPlot correctness:\ncompare closely between the generated plot and the ground truth, the more resemblance the generated plot has compared to the ground truth, the higher the score. The score should be proportionate to the resemblance between the two plots. Ignore color matching. If the plots present the same information but are made in different colors, consider them matching. Capture the resemblance of the main idea of the plot.\nOnly rate the first figure, the second figure is only for reference.\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token.\nFor example [FINAL SCORE]: 40",
        "judge_instruct_task": "You are an excellent judge at evaluating visualization plot according to the given task. You will be giving scores on how well plot image matches the task.\nThe generated plot will be given to you as an image.\nPlease score how well plot matches tha task. Score it on a scale from 0 to 100.\nScoring should be carried out in the following aspect:\nTask adherence: how the plot corresponds to the task given below (begins from [PLOT TASK] token)\nAfter scoring from the above aspect, please give a final score. Do not write anything else. The final score is preceded by the [FINAL SCORE] token. \nFor example [FINAL SCORE]: 40"
    }
}